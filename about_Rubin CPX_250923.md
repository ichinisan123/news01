## NVIDIA Rubin CPX

Based on the sources provided, here is an explanation of the NVIDIA Rubin CPX.

The **NVIDIA Rubin CPX** is a new class of GPU announced by NVIDIA, specifically designed for "massive-context" artificial intelligence (AI) processing. It is described as the first CUDA GPU purpose-built for AI models that need to process and reason across millions of tokens of information at once. This GPU is intended to handle complex, large-scale AI workloads with exceptional speed and efficiency, such as advanced software coding and high-quality generative video creation.

Key features and capabilities of the Rubin CPX include:

*   **Purpose-Built for Massive-Context AI**: The Rubin CPX is engineered to handle AI applications that require massive context windows. For example, processing an hour of video content can require an AI model to handle up to 1 million tokens, while some software development tasks can involve over 100,000 lines of code or even context windows of 100 million tokens, pushing the limits of traditional GPUs.
*   **Performance and Architecture**: Built on the NVIDIA Rubin architecture, the Rubin CPX GPU features a cost-efficient, monolithic die design. It delivers up to 30 petaflops of compute with NVFP4 precision, optimized for high performance and energy efficiency in AI inference tasks. It also offers three times faster "attention" capabilities compared to NVIDIA GB300 NVL72 systems, which improves an AI model's ability to process long sequences of information without a drop in speed.
*   **Memory**: The Rubin CPX is equipped with 128GB of cost-efficient GDDR7 memory to accelerate demanding context-based workloads. This type of RAM is well-suited for handling the input side of inference jobs where memory bandwidth is less critical.
*   **Integrated Design for Video**: For generative video applications, the Rubin CPX integrates four NVENC (encoders) and four NVDEC (decoders) directly on the chip, along with long-context inference processing. This provides unprecedented capabilities for tasks like video search and high-quality generative video.
*   **Role in the Vera Rubin Platform**: The Rubin CPX is a key component of the larger NVIDIA Vera Rubin platform, working alongside NVIDIA Vera CPUs and next-generation Rubin GPUs. It is part of the integrated **NVIDIA Vera Rubin NVL144 CPX** system, a single rack that packs 8 exaflops of AI performance, which is 7.5 times more than the NVIDIA GB300 NVL72 system. This platform also includes 100TB of fast memory and 1.7 petabytes per second of memory bandwidth. A dedicated compute tray will also be available for customers who want to upgrade existing Vera Rubin NVL144 systems.
*   **Economic Impact**: NVIDIA claims the Vera Rubin NVL144 CPX enables companies to monetize at an unprecedented scale, projecting $5 billion in token revenue for every $100 million invested.
*   **Industry Adoption**: AI innovators are exploring how Rubin CPX can accelerate their applications.
    *   **Cursor**, an AI-powered code editor, anticipates using it to deliver "lightning-fast code generation and developer insights".
    *   **Runway**, a generative AI company, sees Rubin CPX as a "major leap in performance" that will support demanding creative workflows for cinematic content.
    *   **Magic**, a company developing AI agents for software engineering, notes that GPUs like the Rubin CPX greatly accelerate their compute workloads for models that use context windows of up to 100 million tokens.
*   **Software Support**: The Rubin CPX will be supported by the complete NVIDIA AI stack, including the NVIDIA Dynamo platform for scaling AI inference and the NVIDIA Nemotronâ„¢ family of multimodal models for AI agents.
*   **Availability**: The NVIDIA Rubin CPX is planned for a 2026 launch and is expected to be available at the end of that year.
